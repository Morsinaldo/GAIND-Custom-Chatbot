{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "**TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task**\n",
    "\n",
    "In this project, we utilized a dataset containing 101 facts about the Premier League from the 2022/23 season, sourced from `theanalyst.com` webpage. This dataset was chosen because we aim to develop a tool that acts as an expert and can provide answers to questions related to this specific league and season.\n",
    "\n",
    "To enhance the question-answering capability of our tool, we employed the Retrieval Augmented Generation technique. This technique supplements the prompt with contextual information from the dataset, enabling the model to provide more accurate and relevant answers to questions posed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eecf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "OPENAI_API_KEY = 'YOUR API KEY'\n",
    "\n",
    "# URLs and file paths\n",
    "SOURCE_URL = 'https://theanalyst.com/eu/2023/05/101-best-premier-league-facts-2022-23'\n",
    "HTML_PAGE_FILEPATH = './html_page.html'\n",
    "CSV_FILEPATH_WITH_EMBEDDINGS = './wikipedia_with_embeddings.csv'\n",
    "\n",
    "# OpenAI Models\n",
    "EMBEDDING_MODEL = 'text-embedding-3-small'\n",
    "COMPLETION_MODEL = 'gpt-3.5-turbo'\n",
    "\n",
    "# Batch size for processing\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "**TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450a55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Union, Dict\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to fetch HTML page from a URL\n",
    "def fetch_html_page(url: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Fetches HTML content from a given URL.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the webpage to fetch.\n",
    "        \n",
    "    Returns:\n",
    "        bytes: The HTML content of the webpage.\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If there is a connection error.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        raise Exception('Connection error')\n",
    "\n",
    "# Save the HTML page to a file\n",
    "with open(HTML_PAGE_FILEPATH, mode='wb') as html_file:\n",
    "    html_page = fetch_html_page(SOURCE_URL)\n",
    "    html_file.write(html_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6490915",
   "metadata": {},
   "source": [
    "### Read HTML Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23732d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from HTML\n",
    "def extract_data_from_html(html_file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts data from an HTML file.\n",
    "    \n",
    "    Args:\n",
    "        html_file_path (str): The file path to the HTML file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    # Parsing the HTML file\n",
    "    with open(html_file_path) as fp:\n",
    "        soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "    # Finding the root DOM node\n",
    "    root_dom_node = soup.find('h2', {'class': 'has-text-align-center wp-block-heading'})\n",
    "\n",
    "    # Extracting month headers\n",
    "    month_headers = [month_header.find_next('strong') for month_header in soup.find_all('h2', {'class': 'has-text-align-center wp-block-heading'})]\n",
    "\n",
    "    current_month = None\n",
    "    data = []\n",
    "\n",
    "    # Loop through DOM nodes to extract data\n",
    "    for node in root_dom_node.find_all_next():\n",
    "        if node in month_headers:\n",
    "            current_month = node.text\n",
    "        elif node.name == 'ul':\n",
    "            data.append(f\"{current_month} 2024 -- {node.find_next('li').text.strip()}\")\n",
    "\n",
    "    # Creating DataFrame from extracted data\n",
    "    df = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f925ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from HTML and displaying DataFrame\n",
    "df = extract_data_from_html(HTML_PAGE_FILEPATH)\n",
    "\n",
    "# Setting display options for DataFrame\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3322046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                         text\n",
      "0                                                                           August 2024 -- On 13 August 2022, Manchester City ended the day top and Manchester United ended the day bottom of the top-flight table for the first time since 29 November 1929.\n",
      "1                                                                                                August 2024 -- Erik ten Hag became the first manager to lose each of his first two games in charge of Manchester United since John Chapman in November 1921.\n",
      "2                                                August 2024 -- Harry Kane netted his 185th Premier League goal for Tottenham Hotspur against Wolves, overtaking Sergio Aguero’s record for Premier League goals for a single club (184 for Manchester City).\n",
      "3                                                           August 2024 -- Brenden Aaronson’s opening goal in Leeds’ 3-0 win against Chelsea was the first time an American player scored under an American manager (Jesse Marsch) in Premier League history.\n",
      "4  August 2024 -- Darwin Núñez came off the bench to score and assist on his Premier League debut for Liverpool against Fulham, only the third player to score and assist as a substitute on debut, along with Sergio Aguero (2011) and Alvaro Morata (2017).\n",
      "(101, 1)\n"
     ]
    }
   ],
   "source": [
    "# Displaying DataFrame and its shape\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2763b",
   "metadata": {},
   "source": [
    "### Create Embedding Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94787ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31cc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset display options for pandas DataFrame\n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f3a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings from OpenAI API\n",
    "def get_embeddings(prompt: Union[str, List[str]], embedding_model: str) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Retrieves embeddings from OpenAI API for the given prompt using the specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        prompt (Union[str, List[str]]): Input prompt or list of prompts.\n",
    "        embedding_model (str): Name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: List of embeddings for the input prompt(s).\n",
    "    \"\"\"\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=prompt if isinstance(prompt, list) else [prompt],\n",
    "        model=embedding_model\n",
    "    )\n",
    "    return [row.embedding for row in response.data]\n",
    "\n",
    "# Function to create embeddings for DataFrame\n",
    "def create_embeddings(df: pd.DataFrame, embedding_model_name: str = EMBEDDING_MODEL, batch_size: int = BATCH_SIZE) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Creates embeddings for the text data in the DataFrame using the specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing text data.\n",
    "        embedding_model_name (str): Name of the embedding model to use.\n",
    "        batch_size (int): Size of batches for processing.\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: List of embeddings corresponding to the text data.\n",
    "    \"\"\"\n",
    "    embeddings_output = []\n",
    "    for idx in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[idx:idx+batch_size]['text'].tolist()\n",
    "        embeddings = get_embeddings(batch, embedding_model_name)\n",
    "        embeddings_output.extend(embeddings)\n",
    "    return embeddings_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8268e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  August 2024 -- On 13 August 2022, Manchester C...   \n",
      "1  August 2024 -- Erik ten Hag became the first m...   \n",
      "2  August 2024 -- Harry Kane netted his 185th Pre...   \n",
      "3  August 2024 -- Brenden Aaronson’s opening goal...   \n",
      "4  August 2024 -- Darwin Núñez came off the bench...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.01703871600329876, 0.007503733970224857, 0...  \n",
      "1  [-0.054760657250881195, -0.011442207731306553,...  \n",
      "2  [0.004939332604408264, -0.01658555120229721, 0...  \n",
      "3  [0.005131910089403391, -0.006789827719330788, ...  \n",
      "4  [-0.055598579347133636, 0.012705056928098202, ...  \n"
     ]
    }
   ],
   "source": [
    "# Add embeddings to DataFrame and save to CSV\n",
    "df['embedding'] = create_embeddings(df)\n",
    "df.to_csv(CSV_FILEPATH_WITH_EMBEDDINGS, sep=',', index=False)\n",
    "\n",
    "# Display DataFrame head\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "**TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_prompt(question: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds a simple prompt for asking a question.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to include in the prompt.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: A list containing a single message with the user role and the provided question.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def build_custom_prompt(question: str, database_df: pd.DataFrame) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds a custom prompt including context for asking a question based on a database DataFrame.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to include in the prompt.\n",
    "        database_df (pd.DataFrame): The DataFrame containing the database of facts.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: A list containing two messages: system message with context and user message with the question.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"\"\"\n",
    "            Anser the question based on provided context below. If the question cannot be answered based on provided context, say \"I don't know the answer\". We have 2024. Context contains facts from season 2022/2023 for English Premier League. Facts are annotated with date and seperated by lines. \n",
    "            Context: \n",
    "                {}\n",
    "            \"\"\".format('\\n\\n'.join(build_custom_context(question, database_df)))\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': question\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def build_custom_context(question: str, database_df: pd.DataFrame, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Builds a custom context for a given question based on the closest facts from a database DataFrame.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question for which the context is being built.\n",
    "        database_df (pd.DataFrame): The DataFrame containing the database of facts.\n",
    "        n (int): The number of closest facts to include in the context.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of closest facts to the question.\n",
    "    \"\"\"\n",
    "    question_embedding = get_embeddings(question, EMBEDDING_MODEL)[0]\n",
    "    \n",
    "    df = database_df.copy()\n",
    "    df[\"distances\"] = df['embedding'].apply(lambda embedding: cosine(embedding, question_embedding))\n",
    "\n",
    "    df.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df.iloc[:n]['text'].tolist()\n",
    "\n",
    "def handle_question(prompt: List[Dict[str, str]], client: OpenAI, model_name: str = COMPLETION_MODEL) -> str:\n",
    "    \"\"\"\n",
    "    Handles a question prompt by generating a response using the specified model.\n",
    "\n",
    "    Args:\n",
    "        prompt (List[Dict[str, str]]): The prompt messages to send to the model.\n",
    "        model_name (str): The name of the completion model to use.\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated by the model.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=prompt,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "**TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55803746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame from CSV file\n",
    "df = pd.read_csv(CSV_FILEPATH_WITH_EMBEDDINGS)\n",
    "\n",
    "# Convert embedding values from string to list of floats\n",
    "df['embedding'] = df['embedding'].apply(lambda value: [float(dim) for dim in value.replace('[', '').replace(']', '').split(',')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " It is not possible to accurately answer this question as the 2022/2023 Premier League season has not yet taken place.\n",
      "\n",
      "Answer with Context: \n",
      " Man City won the Premier League in the 2022/2023 season.\n"
     ]
    }
   ],
   "source": [
    "# Define the question\n",
    "question_1 = 'Who won the Premier League in the 2022/2023 season?'\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(build_simple_prompt(question_1), openai_client))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(build_custom_prompt(question_1, df), openai_client))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " Harry Kane played for Manchester City in the 2022/2023 season.\n",
      "\n",
      "Answer with Context: \n",
      " Harry Kane played for Tottenham Hotspur in the 2022/2023 season.\n"
     ]
    }
   ],
   "source": [
    "# Define the question\n",
    "question_2 = 'Which football team did Harry Kane play for in the 2022/2023 season?'\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(build_simple_prompt(question_2), openai_client))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(build_custom_prompt(question_2, df), openai_client))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42251f",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a93a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " I'm sorry, but I would need more information in order to provide a specific answer to your question. Please provide the name of the sport and teams involved in the match.\n",
      "\n",
      "Answer with Context: \n",
      " Liverpool finished the match with the most competitive win, defeating Manchester United 7-0 in March 2024.\n"
     ]
    }
   ],
   "source": [
    "# Define the question\n",
    "question_3 = 'Which team finished the match with the most competitive win? What was the result? Who was the opponent?'\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(build_simple_prompt(question_3), openai_client))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(build_custom_prompt(question_3, df), openai_client))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831e8b1",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- **Question 1:**: It is evident that the model correctly responded after querying the custom database, indicating its ability to retrieve relevant information when necessary.\n",
    "- **Question 2:**: The model provided an incorrect response to the question when not provided with the context from the custom database. However, upon utilizing the custom database, it furnished a correct response, underscoring the significance of context in response accuracy.\n",
    "- **Question 3:**: It is evident that the model correctly responded after querying the custom database, indicating its ability to retrieve relevant information when necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
